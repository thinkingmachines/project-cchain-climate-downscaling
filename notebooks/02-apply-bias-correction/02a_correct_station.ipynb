{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Standard imports\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Library imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as sc\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xarray as xr\n",
    "\n",
    "# Util imports\n",
    "sys.path.append(\"../../\")\n",
    "import src.climate_downscaling_utils as cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct station data\n",
    "\n",
    "This notebook applies bias correction algorithms on gridded data using station data.\n",
    "\n",
    "**Prerequisite**: Run `notebooks/02-apply-bias-correction/01_overlay_station.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CITY_NAME = \"Zamboanga\"\n",
    "\n",
    "DATE = \"2008-07-01\"  # sample date for debugging\n",
    "YEARS = [2007, 2008, 2009, 2016, 2017, 2018]\n",
    "SHOULD_DEBUG = False\n",
    "PROCESSED_PATH = Path(\"../../data/02-processed\")\n",
    "CORRECTED_PATH = PROCESSED_PATH / \"bias-correction-optimized\"\n",
    "CORRECTED_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "STATION_NC = CORRECTED_PATH / f\"station_{CITY_NAME.lower()}.nc\"\n",
    "GRIDDED_NC = (\n",
    "    PROCESSED_PATH\n",
    "    / f\"input/chirts_chirps_regridded_interpolated_{CITY_NAME.split('_')[0].lower()}.nc\"\n",
    ")\n",
    "GRIDDED_SUBSET_NC = CORRECTED_PATH / f\"gridded_{CITY_NAME.lower()}.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set run parameters\n",
    "- `plot_offset`: margin for x and y bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_params = dict(\n",
    "    tmin=\"CHIRTS minimum temperature\",\n",
    "    tmax=\"CHIRTS maximum temperature\",\n",
    "    precip=\"CHIRPS precipitation\",\n",
    ")\n",
    "\n",
    "method_params = dict(\n",
    "    tmin=\"variance_scaling\",\n",
    "    tmax=\"linear_scaling\",\n",
    "    precip=\"linear_scaling\",\n",
    ")\n",
    "\n",
    "algo_params = dict(\n",
    "    linear_scaling=dict(\n",
    "        name=\"Linear Scaling\",\n",
    "        func=cd.correct_gridded_cmethods,\n",
    "        group=\"time.month\",\n",
    "    ),\n",
    "    variance_scaling=dict(\n",
    "        name=\"Variance Scaling\",\n",
    "        func=cd.correct_gridded_cmethods,\n",
    "        group=\"time.month\",\n",
    "    ),\n",
    "    # delta_method=dict(\n",
    "    #     name=\"Delta Method\",\n",
    "    #     func=cd.correct_gridded_cmethods,\n",
    "    #     group=\"time.month\",\n",
    "    # ),\n",
    "    quantile_mapping=dict(\n",
    "        name=\"Quantile Mapping\",\n",
    "        func=cd.correct_gridded_cmethods,\n",
    "        n_quantiles=10,\n",
    "    ),\n",
    "    detrended_quantile_mapping=dict(\n",
    "        name=\"Detrended Quantile Mapping\",\n",
    "        func=cd.correct_gridded_cmethods,\n",
    "        n_quantiles=1_000,\n",
    "    ),\n",
    "    # quantile_delta_mapping=dict(\n",
    "    #     name=\"Quantile Delta Mapping\",\n",
    "    #     func=cd.correct_gridded_cmethods,\n",
    "    #     n_quantiles=1_000,\n",
    "    # ),\n",
    "    # liu = dict(\n",
    "    #     name=\"Liu et al. (2019)\",\n",
    "    #     func=cd.correct_gridded_liu,\n",
    "    # ),\n",
    "    # zscore = dict(\n",
    "    #    name=\"Z-Score\",\n",
    "    #    func=cd.correct_gridded_zscore,\n",
    "    # ),\n",
    ")\n",
    "\n",
    "# refer to defaults\n",
    "for method, algo_param in algo_params.items():\n",
    "    if \"group\" not in algo_param.keys():\n",
    "        algo_param[\"group\"] = \"time.month\"\n",
    "    if \"n_quantiles\" not in algo_param.keys():\n",
    "        algo_param[\"n_quantiles\"] = 1_000\n",
    "\n",
    "\n",
    "scatterplot_params = dict(\n",
    "    tmin=dict(\n",
    "        variable_name=\"Minimum Temperature\",\n",
    "        units=\"°C\",\n",
    "        plot_offset=2.5,\n",
    "        color=\"firebrick\",\n",
    "    ),\n",
    "    tmax=dict(\n",
    "        variable_name=\"Maximum Temperature\",\n",
    "        units=\"°C\",\n",
    "        plot_offset=1,\n",
    "        color=\"firebrick\",\n",
    "    ),\n",
    "    precip=dict(\n",
    "        variable_name=\"Precipitation\",\n",
    "        units=\"mm/day\",\n",
    "        plot_offset=10,\n",
    "        color=\"dodgerblue\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ds = xr.open_dataset(STATION_NC, engine=\"scipy\")\n",
    "gridded_ds = xr.open_dataset(GRIDDED_NC, engine=\"scipy\")\n",
    "gridded_subset_ds = xr.open_dataset(GRIDDED_SUBSET_NC, engine=\"scipy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded_subset_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_lat = station_ds[\"lat\"].item()\n",
    "station_lon = station_ds[\"lon\"].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded_ds.isel(time=gridded_ds.time.dt.year.isin(YEARS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliberate variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_list = []\n",
    "corrected_ds = xr.Dataset(data_vars=None)\n",
    "for var, title in variable_params.items():\n",
    "    print(f\"Now doing {title}\")\n",
    "\n",
    "    if var == \"precip\":\n",
    "        gridded_da = gridded_ds.isel(time=gridded_ds.time.dt.year.isin(YEARS))[var]\n",
    "        gridded_subset_da = gridded_subset_ds.isel(\n",
    "            time=gridded_subset_ds.time.dt.year.isin(YEARS)\n",
    "        )[var]\n",
    "        station_da = station_ds.isel(time=station_ds.time.dt.year.isin(YEARS))[var]\n",
    "    else:\n",
    "        gridded_da = gridded_ds.isel(time=gridded_ds.time.dt.year.isin(YEARS))[var]  #\n",
    "        gridded_subset_da = gridded_subset_ds.isel(\n",
    "            time=gridded_subset_ds.time.dt.year.isin(YEARS)\n",
    "        )[var]\n",
    "        station_da = station_ds.isel(time=station_ds.time.dt.year.isin(YEARS))[var]\n",
    "\n",
    "    if SHOULD_DEBUG:\n",
    "        gridded_da.sel(time=DATE, method=\"nearest\").plot()\n",
    "        plt.plot(station_lon, station_lat, \"o\")\n",
    "        plt.show()\n",
    "\n",
    "        gridded_subset_da.sel(time=DATE, method=\"nearest\").plot()\n",
    "        plt.plot(station_lon, station_lat, \"o\")\n",
    "        plt.show()\n",
    "\n",
    "        gridded_subset_da.plot.hist(bins=15)\n",
    "        plt.show()\n",
    "\n",
    "    algo_param = algo_params[method_params[var]]\n",
    "    print(f\"Now doing {algo_param['name']} bias correction\")\n",
    "\n",
    "    if algo_param[\"name\"] == \"Liu et al. (2019)\" or algo_param[\"name\"] == \"Z-Score\":\n",
    "        corrected_da = algo_param[\"func\"](\n",
    "            gridded_subset_da.sel(time=DATE, method=\"nearest\"),\n",
    "            station_da=station_da.sel(time=DATE, method=\"nearest\"),\n",
    "            std_scale=0.1,\n",
    "            should_plot=SHOULD_DEBUG,\n",
    "        )\n",
    "    else:\n",
    "        corrected_da = algo_param[\"func\"](\n",
    "            gridded_da=gridded_subset_da,\n",
    "            station_da=station_da[:, 0, 0].drop_vars([\"lat\", \"lon\"]),\n",
    "            method=method_params[var],\n",
    "            n_quantiles=algo_param[\"n_quantiles\"],\n",
    "            group=algo_param[\"group\"],\n",
    "            should_plot=SHOULD_DEBUG,\n",
    "        )\n",
    "\n",
    "    corrected_ds[var] = corrected_da\n",
    "\n",
    "    station_aligned_da, corrected_aligned_da = xr.align(\n",
    "        station_da.mean(dim=[\"lat\", \"lon\"], skipna=True).dropna(dim=\"time\"),\n",
    "        corrected_da.mean(dim=[\"lat\", \"lon\"], skipna=True).dropna(dim=\"time\"),\n",
    "        join=\"inner\",\n",
    "    )\n",
    "\n",
    "    corr, pval = sc.pearsonr(station_aligned_da, corrected_aligned_da)\n",
    "    rmse = mean_squared_error(station_aligned_da, corrected_aligned_da, squared=False)\n",
    "\n",
    "    stats_list.append(\n",
    "        dict(var=var, method=method_params[var], corr=corr, pval=pval, rmse=rmse)\n",
    "    )\n",
    "\n",
    "    if SHOULD_DEBUG:\n",
    "        gridded_subset_slice_da = gridded_subset_da.sel(time=DATE, method=\"nearest\")\n",
    "        corrected_slice_da = corrected_da.sel(time=DATE, method=\"nearest\")\n",
    "\n",
    "        plot_min = min([corrected_slice_da.min(), gridded_subset_slice_da.min()]).values\n",
    "        plot_max = max([corrected_slice_da.max(), gridded_subset_slice_da.max()]).values\n",
    "\n",
    "        gridded_subset_slice_da.plot(vmin=plot_min, vmax=plot_max)\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "        corrected_slice_da.plot(vmin=plot_min, vmax=plot_max)\n",
    "        plt.title(f\"Corrected {title}\\n{algo_param['name']}\")\n",
    "        plt.show()\n",
    "\n",
    "        abs(corrected_slice_da - gridded_subset_slice_da).plot(cmap=\"RdYlGn\")\n",
    "        plt.title(\n",
    "            f\"Difference between corrected and uncorrected\\n{title}\\n{algo_param['name']}\"\n",
    "        )\n",
    "        plt.show()\n",
    "stats_df = pd.DataFrame(stats_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-quantiles variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats_list = []\n",
    "# corrected_ds = xr.Dataset(data_vars=None)\n",
    "# for var, title in variable_params.items():\n",
    "#     print(f\"Now doing {title}\")\n",
    "\n",
    "#     if var == \"precip\":\n",
    "#         gridded_da = gridded_ds.isel(time=gridded_ds.time.dt.year.isin(YEARS))[var]\n",
    "#         gridded_subset_da = gridded_subset_ds.isel(time=gridded_subset_ds.time.dt.year.isin(YEARS))[var]\n",
    "#         station_da = station_ds.isel(time=station_ds.time.dt.year.isin(YEARS))[var]\n",
    "#     else:\n",
    "#         gridded_da = gridded_ds.isel(time=gridded_ds.time.dt.year.isin(YEARS))[var]  #\n",
    "#         gridded_subset_da = gridded_subset_ds.isel(time=gridded_subset_ds.time.dt.year.isin(YEARS))[var]\n",
    "#         station_da = station_ds.isel(time=station_ds.time.dt.year.isin(YEARS))[var]\n",
    "\n",
    "#     if SHOULD_DEBUG:\n",
    "#         gridded_da.sel(time=DATE, method=\"nearest\").plot()\n",
    "#         plt.plot(station_lon, station_lat, \"o\")\n",
    "#         plt.show()\n",
    "\n",
    "#         gridded_subset_da.sel(time=DATE, method=\"nearest\").plot()\n",
    "#         plt.plot(station_lon, station_lat, \"o\")\n",
    "#         plt.show()\n",
    "\n",
    "#         gridded_subset_da.plot.hist(bins=15)\n",
    "#         plt.show()\n",
    "\n",
    "#     for method,algo_param in algo_params.items():\n",
    "#         print(f\"Now doing {algo_param['name']} bias correction\")\n",
    "\n",
    "#         if algo_param[\"name\"] == \"Liu et al. (2019)\" or algo_param[\"name\"] == \"Z-Score\":\n",
    "#             corrected_da = algo_param[\"func\"](\n",
    "#                 gridded_subset_da.sel(time=DATE, method=\"nearest\"),\n",
    "#                 station_da=station_da.sel(time=DATE, method=\"nearest\"),\n",
    "#                 std_scale=0.1,\n",
    "#                 should_plot=SHOULD_DEBUG,\n",
    "#             )\n",
    "#         else:\n",
    "#             corrected_da = algo_param[\"func\"](\n",
    "#                 gridded_da=gridded_subset_da,\n",
    "#                 station_da=station_da[:, 0, 0].drop_vars([\"lat\", \"lon\"]),\n",
    "#                 method=method,\n",
    "#                 n_quantiles=algo_param[\"n_quantiles\"],\n",
    "#                 group=algo_param[\"group\"],\n",
    "#                 should_plot=SHOULD_DEBUG,\n",
    "#             )\n",
    "\n",
    "#         corrected_ds[var] = corrected_da\n",
    "\n",
    "#         station_aligned_da, corrected_aligned_da = xr.align(\n",
    "#             station_da.mean(dim=[\"lat\", \"lon\"], skipna=True).dropna(dim=\"time\"),\n",
    "#             corrected_da.mean(dim=[\"lat\", \"lon\"], skipna=True).dropna(dim=\"time\"),\n",
    "#             join=\"inner\",\n",
    "#         )\n",
    "\n",
    "#         corr, pval = sc.pearsonr(station_aligned_da, corrected_aligned_da)\n",
    "#         rmse = mean_squared_error(station_aligned_da, corrected_aligned_da, squared=False)\n",
    "\n",
    "#         stats_list.append(\n",
    "#             dict(\n",
    "#                 var=var,\n",
    "#                 method=method,\n",
    "#                 corr=corr,\n",
    "#                 pval=pval,\n",
    "#                 rmse=rmse\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#         if SHOULD_DEBUG:\n",
    "#             gridded_subset_slice_da = gridded_subset_da.sel(time=DATE, method=\"nearest\")\n",
    "#             corrected_slice_da = corrected_da.sel(time=DATE, method=\"nearest\")\n",
    "\n",
    "#             plot_min = min(\n",
    "#                 [corrected_slice_da.min(), gridded_subset_slice_da.min()]\n",
    "#             ).values\n",
    "#             plot_max = max(\n",
    "#                 [corrected_slice_da.max(), gridded_subset_slice_da.max()]\n",
    "#             ).values\n",
    "\n",
    "#             gridded_subset_slice_da.plot(vmin=plot_min, vmax=plot_max)\n",
    "#             plt.title(title)\n",
    "#             plt.show()\n",
    "\n",
    "#             corrected_slice_da.plot(vmin=plot_min, vmax=plot_max)\n",
    "#             plt.title(f\"Corrected {title}\\n{algo_param['name']}\")\n",
    "#             plt.show()\n",
    "\n",
    "#             abs(corrected_slice_da - gridded_subset_slice_da).plot(cmap=\"RdYlGn\")\n",
    "#             plt.title(\n",
    "#                 f\"Difference between corrected and uncorrected\\n{title}\\n{algo_param['name']}\"\n",
    "#             )\n",
    "#             plt.show()\n",
    "# stats_df = pd.DataFrame(stats_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ds.to_netcdf(\n",
    "    CORRECTED_PATH / f\"corrected_subset_{CITY_NAME.lower()}.nc\",\n",
    "    engine=\"scipy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantiles variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats_list = []\n",
    "# for var, title in variable_params.items():\n",
    "#     print(f\"Now doing {title}\")\n",
    "\n",
    "#     if var == \"precip\":\n",
    "#         gridded_da = gridded_ds.isel(time=gridded_ds.time.dt.year.isin(YEARS))[var]\n",
    "#         gridded_subset_da = gridded_subset_ds.isel(time=gridded_subset_ds.time.dt.year.isin(YEARS))[var]\n",
    "#         station_da = station_ds.isel(time=station_ds.time.dt.year.isin(YEARS))[var]\n",
    "#     else:\n",
    "#         gridded_da = gridded_ds.isel(time=gridded_ds.time.dt.year.isin(YEARS))[var]  #\n",
    "#         gridded_subset_da = gridded_subset_ds.isel(time=gridded_subset_ds.time.dt.year.isin(YEARS))[var]\n",
    "#         station_da = station_ds.isel(time=station_ds.time.dt.year.isin(YEARS))[var]\n",
    "\n",
    "#     if SHOULD_DEBUG:\n",
    "#         gridded_da.sel(time=DATE, method=\"nearest\").plot()\n",
    "#         plt.plot(station_lon, station_lat, \"o\")\n",
    "#         plt.show()\n",
    "\n",
    "#         gridded_subset_da.sel(time=DATE, method=\"nearest\").plot()\n",
    "#         plt.plot(station_lon, station_lat, \"o\")\n",
    "#         plt.show()\n",
    "\n",
    "#         gridded_subset_da.plot.hist(bins=15)\n",
    "#         plt.show()\n",
    "\n",
    "#     for method,algo_param in algo_params.items():\n",
    "#         print(f\"Now doing {algo_param['name']} bias correction\")\n",
    "\n",
    "#         for n_quantiles in quantiles:\n",
    "\n",
    "#             if algo_param[\"name\"] == \"Liu et al. (2019)\" or algo_param[\"name\"] == \"Z-Score\":\n",
    "#                 corrected_da = algo_param[\"func\"](\n",
    "#                     gridded_subset_da.sel(time=DATE, method=\"nearest\"),\n",
    "#                     station_da=station_da.sel(time=DATE, method=\"nearest\"),\n",
    "#                     std_scale=0.1,\n",
    "#                     should_plot=SHOULD_DEBUG,\n",
    "#                 )\n",
    "#             else:\n",
    "#                 corrected_da = algo_param[\"func\"](\n",
    "#                     gridded_da=gridded_subset_da,\n",
    "#                     station_da=station_da[:, 0, 0].drop_vars([\"lat\", \"lon\"]),\n",
    "#                     method=method_params[var],\n",
    "#                     n_quantiles=n_quantiles,\n",
    "#                     group=algo_param[\"group\"],\n",
    "#                     should_plot=SHOULD_DEBUG,\n",
    "#                 )\n",
    "\n",
    "#             station_aligned_da, corrected_aligned_da = xr.align(\n",
    "#                 station_da.mean(dim=[\"lat\", \"lon\"], skipna=True).dropna(dim=\"time\"),\n",
    "#                 corrected_da.mean(dim=[\"lat\", \"lon\"], skipna=True).dropna(dim=\"time\"),\n",
    "#                 join=\"inner\",\n",
    "#             )\n",
    "\n",
    "#             corr, pval = sc.pearsonr(station_aligned_da, corrected_aligned_da)\n",
    "#             rmse = mean_squared_error(station_aligned_da, corrected_aligned_da, squared=False)\n",
    "\n",
    "#             stats_list.append(\n",
    "#                 dict(\n",
    "#                     var=var,\n",
    "#                     method=method_params[var],\n",
    "#                     n_quantiles=n_quantiles,\n",
    "#                     corr=corr,\n",
    "#                     pval=pval,\n",
    "#                     rmse=rmse\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "# stats_df = pd.DataFrame(stats_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.to_parquet(CORRECTED_PATH / f\"stats_{CITY_NAME.lower()}.parquet\")\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fontsize=16\n",
    "# plt.plot(stats_df[\"n_quantiles\"],stats_df[\"rmse\"], \"o-\")\n",
    "# ax = plt.gca()\n",
    "# ax.semilogx()\n",
    "# plt.xlabel(\"Number of quantiles\", fontsize=fontsize)\n",
    "# plt.ylabel(\"RMSE (mm/day)\", fontsize=fontsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# station_aligned_da, corrected_aligned_da = xr.align(\n",
    "#     station_da.mean(dim=[\"lat\", \"lon\"], skipna=True).dropna(dim=\"time\"),\n",
    "#     corrected_da.mean(dim=[\"lat\", \"lon\"], skipna=True).dropna(dim=\"time\"),\n",
    "#     join=\"inner\",\n",
    "# )\n",
    "\n",
    "# corr, pval = sc.pearsonr(station_aligned_da, corrected_aligned_da)\n",
    "# rmse = mean_squared_error(station_aligned_da, corrected_aligned_da, squared=False)\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1)\n",
    "# plot_min = min(station_aligned_da.min(), corrected_aligned_da.min()) - scatterplot_params[var][\"plot_offset\"]\n",
    "# plot_max = max(station_aligned_da.max(), corrected_aligned_da.max()) + scatterplot_params[var][\"plot_offset\"]\n",
    "# ax.plot(\n",
    "#     [plot_min - scatterplot_params[var][\"plot_offset\"], plot_max + scatterplot_params[var][\"plot_offset\"]],\n",
    "#     [plot_min - scatterplot_params[var][\"plot_offset\"], plot_max + scatterplot_params[var][\"plot_offset\"]],\n",
    "#     \"k-\",\n",
    "# )\n",
    "# ax.plot(station_aligned_da, corrected_aligned_da, \"o\", color=scatterplot_params[var][\"color\"])\n",
    "# ax.set_aspect(1)\n",
    "# plt.xlabel(f\"Station {scatterplot_params[var]['variable_name']} ({scatterplot_params[var]['units']})\")\n",
    "# plt.ylabel(f\"Corrected {scatterplot_params[var]['variable_name']} ({scatterplot_params[var]['units']})\")\n",
    "# plt.title(\n",
    "#     f\"Scatterplot of Corrected vs. Station {scatterplot_params[var]['variable_name']}\\ncorr: {corr:.3f} pval: {pval:.3f}\\nrmse: {rmse:.3f} {scatterplot_params[var]['units']}\"\n",
    "# )\n",
    "# plt.xlim(plot_min, plot_max)\n",
    "# plt.ylim(plot_min, plot_max)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_time = station_aligned_da[\"time\"].to_pandas().reset_index()\n",
    "# df_time[\"year_month\"] = pd.to_datetime(df_time[\"time\"], format=\"%Y-%m-%d\").dt.strftime(\"%Y-%m\")\n",
    "# df_time[\"year_month\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_dict = dict(\n",
    "#     tmin=\"orange\",\n",
    "#     tmax=\"firebrick\",\n",
    "#     precip=\"dodgerblue\",\n",
    "# )\n",
    "\n",
    "# method_dict = dict(\n",
    "#     linear_scaling=\"o\",\n",
    "#     variance_scaling=\"*\",\n",
    "#     delta_method=\"^\",\n",
    "#     quantile_mapping=\"s\",\n",
    "#     quantile_delta_mapping=\"D\",\n",
    "# )\n",
    "\n",
    "# for var in stats_df[\"var\"].unique():\n",
    "#     for method in stats_df[\"method\"].unique():\n",
    "#         corr_n = stats_df.where((stats_df[\"var\"]==var)&(stats_df[\"method\"]==method)).dropna()[\"corr\"]\n",
    "#         rmse_n = stats_df.where((stats_df[\"var\"]==var)&(stats_df[\"method\"]==method)).dropna()[\"rmse\"]\n",
    "#         plt.plot(\n",
    "#             corr_n,\n",
    "#             rmse_n,\n",
    "#             marker=method_dict[method],\n",
    "#             color=color_dict[var],\n",
    "#             label=f\"{var}-{method}\",\n",
    "#             alpha=0.5,\n",
    "#         )\n",
    "# #plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot selected dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for slice_date in [f\"2008-{i:02d}-20\" for i in range(7, 12 + 1)]:\n",
    "#     print(slice_date)\n",
    "#     gridded_subset_slice_da = gridded_subset_da.sel(time=slice_date)\n",
    "#     corrected_slice_da = corrected_da.sel(time=slice_date)\n",
    "\n",
    "#     plot_min = min([corrected_slice_da.min(), gridded_subset_slice_da.min()]).values\n",
    "#     plot_max = max([corrected_slice_da.max(), gridded_subset_slice_da.max()]).values\n",
    "\n",
    "#     gridded_subset_slice_da.plot(vmin=plot_min, vmax=plot_max)\n",
    "#     plt.title(f\"{slice_date}\\n{title}\")\n",
    "#     plt.show()\n",
    "\n",
    "#     corrected_slice_da.plot(vmin=plot_min, vmax=plot_max)\n",
    "#     plt.title(\n",
    "#         f\"{slice_date}\\nCorrected {title}\\n{algo_param['name']}\\nStation reading: {station_da.sel(time=slice_date).mean().item()}\"\n",
    "#     )\n",
    "#     plt.show()\n",
    "\n",
    "#     (corrected_slice_da - gridded_subset_slice_da).plot(cmap=\"RdYlGn\")\n",
    "#     plt.title(\n",
    "#         f\"{slice_date}\\nDifference between corrected and uncorrected\\n{title}\\n{algo_param['name']}\"\n",
    "#     )\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-downscaling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
