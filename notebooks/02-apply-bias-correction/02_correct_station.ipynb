{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Standard imports\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Library imports\n",
    "from cmethods import adjust\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n",
    "# Util imports\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct station data\n",
    "\n",
    "This notebook applies bias correction algorithms on gridded data using station data.\n",
    "\n",
    "**Prerequisite**: Run `notebooks/02-apply-bias-correction/01_overlay_station.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CITY_NAME = \"Dagupan\"\n",
    "DATE = \"2008-07-01\"\n",
    "SHOULD_DEBUG = False\n",
    "\n",
    "PROCESSED_PATH = Path(\"../../data/02-processed\")\n",
    "CORRECTED_PATH = PROCESSED_PATH / \"bias-correction\"\n",
    "\n",
    "STATION_NC = CORRECTED_PATH / f\"station_{CITY_NAME.lower()}.nc\"\n",
    "GRIDDED_NC = (\n",
    "    PROCESSED_PATH\n",
    "    / f\"input/chirts_chirps_regridded_interpolated_{CITY_NAME.lower()}.nc\"\n",
    ")\n",
    "GRIDDED_SUBSET_NC = CORRECTED_PATH / f\"gridded_{CITY_NAME.lower()}.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile mapping\n",
    "TODO: Transfer to `climate_downscaling_utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_gridded_quantile_mapping(\n",
    "    gridded_da: xr.DataArray,\n",
    "    station_da: xr.DataArray,\n",
    "    method: str = \"quantile_delta_mapping\",\n",
    "    n_quantiles: int = 1_000,\n",
    "    offset: float = 1e-12,\n",
    "    should_plot: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply bias correction for a grid within the influence of a station.\n",
    "    First record the pixelwise deviation to the spatial mean (multiplicative if rainfall and additive otherwise) per timestep.\n",
    "    Then apply the bias correction.\n",
    "    Lastly, reapply the deviation to preserve the spatial variability.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gridded_da : xarray DataArray\n",
    "        Contains the gridded variables.\n",
    "\n",
    "    station_da : xarray DataArray\n",
    "        Contains the variables for a single station.\n",
    "\n",
    "    method : string\n",
    "        Bias correction method under the adjust function of the cmethods package.\n",
    "        Default is \"quantile_delta_mapping\".\n",
    "\n",
    "    n_quantiles : int\n",
    "        Optional, number of quantiles for \"quantile_delta_mapping\".\n",
    "        Default is 1_000.\n",
    "\n",
    "    offset : float\n",
    "        Numerical offset for calculating the deviation.\n",
    "        Default is 1 x 10^(-12).\n",
    "\n",
    "    should_plot : bool\n",
    "        If True, plots the frequency distributions.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xarray DataArray\n",
    "    \"\"\"\n",
    "    bias_correction_kind = \"*\" if gridded_da.name == \"precip\" else \"+\"\n",
    "\n",
    "    # get the spatial mean\n",
    "    gridded_mean_da = gridded_da.mean(dim=[\"lat\", \"lon\"], skipna=True)\n",
    "\n",
    "    if gridded_da.name == \"precip\":\n",
    "        gridded_deviation_da = gridded_da / max(gridded_mean_da, offset)\n",
    "    else:\n",
    "        gridded_deviation_da = gridded_da - gridded_mean_da\n",
    "\n",
    "    # observation (obs) is the station_da timeseries\n",
    "    # historical simulation (simh) is gridded_da since it has the bias\n",
    "    # predicted simulation (simp) is also gridded_da since we are correcting that data\n",
    "    corrected_da = adjust(\n",
    "        method=method,\n",
    "        obs=station_da,\n",
    "        simh=gridded_mean_da,\n",
    "        simp=gridded_mean_da,\n",
    "        n_quantiles=n_quantiles,\n",
    "        kind=bias_correction_kind,\n",
    "    )\n",
    "\n",
    "    corrected_3d_da = corrected_da.expand_dims(\n",
    "        dim=dict(\n",
    "            lat=gridded_da[\"lat\"].shape[0],\n",
    "            lon=gridded_da[\"lon\"].shape[0],\n",
    "        )\n",
    "    ).assign_coords(\n",
    "        dict(\n",
    "            lat=gridded_da[\"lat\"],\n",
    "            lon=gridded_da[\"lon\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if gridded_da.name == \"precip\":\n",
    "        corrected_variability_da = corrected_3d_da * gridded_deviation_da\n",
    "    else:\n",
    "        corrected_variability_da = corrected_3d_da + gridded_deviation_da\n",
    "\n",
    "    return corrected_variability_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_params = dict(\n",
    "    tmin=\"CHIRTS minimum temperature\",\n",
    "    # tmax=\"CHIRTS maximum temperature\",\n",
    "    # precip=\"CHIRPS precipitation\",\n",
    ")\n",
    "\n",
    "algo_params = [\n",
    "    dict(\n",
    "        name=\"Quantile Delta Mapping\",\n",
    "        func=correct_gridded_quantile_mapping,\n",
    "    ),\n",
    "    # dict(\n",
    "    #     name=\"Liu et al. (2019)\",\n",
    "    #     func=cd.correct_gridded_liu,\n",
    "    # ),\n",
    "    # dict(\n",
    "    #    name=\"Z-Score\",\n",
    "    #    func=cd.correct_gridded_zscore,\n",
    "    # ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ds = xr.open_dataset(STATION_NC, engine=\"scipy\")\n",
    "gridded_ds = xr.open_dataset(GRIDDED_NC, engine=\"scipy\")\n",
    "gridded_subset_ds = xr.open_dataset(GRIDDED_SUBSET_NC, engine=\"scipy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_lat = station_ds[\"lat\"].item()\n",
    "station_lon = station_ds[\"lon\"].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var, title in variable_params.items():\n",
    "    print(f\"Now doing {title}\")\n",
    "\n",
    "    gridded_da = gridded_ds[var]  # .sel(time=DATE, method=\"nearest\")\n",
    "    gridded_subset_da = gridded_subset_ds[var]  # .sel(time=DATE, method=\"nearest\")\n",
    "\n",
    "    if SHOULD_DEBUG:\n",
    "        gridded_da.plot()\n",
    "        plt.plot(station_lon, station_lat, \"o\")\n",
    "        plt.show()\n",
    "\n",
    "        gridded_subset_da.plot()\n",
    "        plt.plot(station_lon, station_lat, \"o\")\n",
    "        plt.show()\n",
    "\n",
    "        gridded_subset_da.plot.hist(bins=15)\n",
    "        plt.show()\n",
    "\n",
    "    for algo_param in algo_params:\n",
    "        print(f\"Now doing {algo_param['name']} bias correction\")\n",
    "\n",
    "        if algo_param[\"name\"] == \"Quantile Delta Mapping\":\n",
    "            corrected_da = algo_param[\"func\"](\n",
    "                gridded_subset_da,\n",
    "                station_da=station_ds[var],  # .sel(time=DATE, method=\"nearest\"),\n",
    "                should_plot=SHOULD_DEBUG,\n",
    "            )\n",
    "    else:\n",
    "        corrected_da = algo_param[\"func\"](\n",
    "            gridded_subset_da,\n",
    "            station_da=station_ds[var].sel(time=DATE, method=\"nearest\"),\n",
    "            std_scale=0.1,\n",
    "            should_plot=SHOULD_DEBUG,\n",
    "        )\n",
    "\n",
    "        if SHOULD_DEBUG:\n",
    "            plot_min = min([corrected_da.min(), gridded_subset_da.min()]).values\n",
    "            plot_max = max([corrected_da.max(), gridded_subset_da.max()]).values\n",
    "\n",
    "            gridded_subset_da.plot(vmin=plot_min, vmax=plot_max)\n",
    "            plt.title(title)\n",
    "            plt.show()\n",
    "\n",
    "            corrected_da.plot(vmin=plot_min, vmax=plot_max)\n",
    "            plt.title(f\"Corrected {title}\\n{algo_param['name']}\")\n",
    "            plt.show()\n",
    "\n",
    "            (corrected_da - gridded_subset_da).plot(cmap=\"RdBu\")\n",
    "            plt.title(\n",
    "                f\"Difference between corrected and uncorrected\\n{title}\\n{algo_param['name']}\"\n",
    "            )\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded_da = gridded_subset_da\n",
    "station_da = station_ds[var][:, 0, 0].drop_vars(\n",
    "    [\"lat\", \"lon\"]\n",
    ")  # .sel(time=DATE, method=\"nearest\")\n",
    "method = \"quantile_delta_mapping\"\n",
    "n_quantiles = 1_000\n",
    "offset = 1e-12\n",
    "\n",
    "bias_correction_kind = \"*\" if gridded_da.name == \"precip\" else \"+\"\n",
    "\n",
    "# get the spatial mean\n",
    "gridded_mean_da = gridded_da.mean(dim=[\"lat\", \"lon\"], skipna=True)\n",
    "\n",
    "if gridded_da.name == \"precip\":\n",
    "    gridded_deviation_da = gridded_da / max(gridded_mean_da, offset)\n",
    "else:\n",
    "    gridded_deviation_da = gridded_da - gridded_mean_da\n",
    "\n",
    "# align DataArrays to match dimensions\n",
    "station_aligned_da, gridded_aligned_da = xr.align(\n",
    "    station_da, gridded_mean_da, join=\"inner\"\n",
    ")\n",
    "\n",
    "# observation (obs) is the station_da timeseries\n",
    "# historical simulation (simh) is gridded_da since it has the bias\n",
    "# predicted simulation (simp) is also gridded_da since we are correcting that data\n",
    "corrected_ds = adjust(\n",
    "    method=method,\n",
    "    obs=station_aligned_da,\n",
    "    simh=gridded_aligned_da,\n",
    "    simp=gridded_aligned_da,\n",
    "    n_quantiles=n_quantiles,\n",
    "    kind=bias_correction_kind,\n",
    ")\n",
    "\n",
    "# nlat = gridded_da[\"lat\"].shape[0]\n",
    "# nlon = gridded_da[\"lon\"].shape[0]\n",
    "# ntime = gridded_aligned_da.values.shape[0]\n",
    "# corrected_3d_da = xr.DataArray(\n",
    "#     nlat*[\n",
    "#         nlon*[\n",
    "#             corrected_ds[gridded_da.name].values[:,0,0]\n",
    "#         ]\n",
    "#     ],\n",
    "#     dims=dict(\n",
    "#         lat=gridded_da[\"lat\"],\n",
    "#         lon=gridded_da[\"lon\"],\n",
    "#         time=corrected_ds[\"time\"],\n",
    "#     ),\n",
    "#     coords=dict(\n",
    "#         lat=gridded_da[\"lat\"],\n",
    "#         lon=gridded_da[\"lon\"],\n",
    "#         time=corrected_ds[\"time\"],\n",
    "#     )\n",
    "# )\n",
    "\n",
    "corrected_3d_da = (\n",
    "    corrected_ds\n",
    "    # .drop_dims(\n",
    "    #     [\n",
    "    #         \"lat\",\n",
    "    #         \"lon\",\n",
    "    #     ]\n",
    "    # )\n",
    "    .expand_dims(\n",
    "        dim=dict(\n",
    "            lat=gridded_da[\"lat\"].shape[0],\n",
    "            lon=gridded_da[\"lon\"].shape[0],\n",
    "        ),\n",
    "        # create_index_for_new_dim=False,\n",
    "    ).transpose(\"time\", \"lat\", \"lon\")\n",
    "    # .assign_coords(\n",
    "    #     dict(\n",
    "    #         lat=gridded_da[\"lat\"],\n",
    "    #         lon=gridded_da[\"lon\"],\n",
    "    #     )\n",
    "    # )\n",
    ")\n",
    "\n",
    "if gridded_da.name == \"precip\":\n",
    "    corrected_variability_da = corrected_3d_da * gridded_deviation_da\n",
    "else:\n",
    "    corrected_variability_da = corrected_3d_da + gridded_deviation_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_variability_da[\"tmin\"][0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded_deviation_da[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_da.sel(time=\"2008-07-01\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_variability_da.sel(time=\"2008-07-01\")[\"tmin\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded_subset_ds.sel(time=\"2008-07-01\")[\"tmin\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(corrected_variability_da.sel(time=\"2008-07-01\") - gridded_da.sel(time=\"2008-07-01\"))[\n",
    "    \"tmin\"\n",
    "].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_aligned_da[:, 0, 0].drop_vars([\"lat\", \"lon\"])  # .drop_indexes([\"lat\",\"lon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded_aligned_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ds.reindex(\n",
    "    dict(\n",
    "        lat=gridded_da[\"lat\"],\n",
    "        lon=gridded_da[\"lon\"],\n",
    "    ),\n",
    "    method=\"ffill\",\n",
    ")[\"tmin\"][0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_variability_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded_subset_ds[\"tmin\"][0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_variability_da[\"tmin\"][:, :, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(corrected_variability_da[\"tmin\"][:, :, 0] - gridded_subset_ds[\"tmin\"][0]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded_subset_ds[\"tmin\"][0].mean(dim=[\"lat\", \"lon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_3d_da[\"tmin\"][:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_3d_da[\"tmin\"][:, :, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded_deviation_da[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded_mean_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = xr.align(station_da, gridded_mean_da, join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-downscaling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
