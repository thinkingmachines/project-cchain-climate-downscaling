{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download CHIRTS files\n",
    "\n",
    "\n",
    "\n",
    "This notebook goes through the process of downloading [CHIRTS daily Tmin and Tmax daily data](https://iridl.ldeo.columbia.edu/SOURCES/.UCSB/.CHIRTS/.v1.0/.daily/.global/.0p05/index.html?Set-Language=fr) available per year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEST_PATH = Path(\"../../data/01-raw/chirts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOG_PATH = Path(\"../../logs/\")\n",
    "\n",
    "# Configure logger\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, format=\"{time} {level} {message}\", level=\"INFO\")\n",
    "\n",
    "# Configure daily rotation for file logging\n",
    "daily_sink_file_fmt = LOG_PATH / \"chirts_{time:YYYY-MM-DD}.log\"\n",
    "logger.add(\n",
    "    daily_sink_file_fmt,\n",
    "    rotation=\"00:00\",\n",
    "    format=\"{time} {level} {message}\",\n",
    "    level=\"INFO\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create download function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, save_path):\n",
    "    file_name = str(save_path).split('/')[-1]\n",
    "    logger.info(\n",
    "        \"===========================================================================================\"\n",
    "    )\n",
    "    logger.info(f\"Downloading: {file_name}\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024 * 1024  # 1 Megabyte\n",
    "    logger.info(f\"Total size: {(total_size/ block_size):.2f} MB\")\n",
    "    progress_bar = tqdm(total=total_size, unit='iB', unit_scale=True)\n",
    "    with open(save_path, 'wb') as f:\n",
    "        for data in response.iter_content(block_size):\n",
    "            progress_bar.update(len(data))\n",
    "            f.write(data)\n",
    "    progress_bar.close()\n",
    "    \n",
    "    if total_size != 0 and progress_bar.n != total_size:\n",
    "        logger.error(f\"Downloading {file_name}  failed.\")\n",
    "    else:\n",
    "        logger.success(f\"{file_name} successfully downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download yearly files and subset to PH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PH_BBOX = (116.5, 4.25, 127, 21.5)\n",
    "years = [2013,2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26T16:01:05.796690+0800 INFO ===========================================================================================\n",
      "2024-03-26T16:01:05.798647+0800 INFO Downloading: Tmin_2013.nc\n",
      "2024-03-26T16:01:07.586977+0800 INFO Total size: 26069.61 MB\n",
      "  0%|          | 2.10M/27.3G [00:01<4:39:09, 1.63MiB/s]2024-03-26T16:01:09.082865+0800 ERROR Process interrupted using keyboard.\n",
      "  0%|          | 2.10M/27.3G [00:01<5:24:58, 1.40MiB/s]\n",
      "2024-03-26T16:01:09.085423+0800 INFO ===========================================================================================\n",
      "2024-03-26T16:01:09.086233+0800 INFO Downloading: Tmin_2014.nc\n",
      "2024-03-26T16:01:09.753939+0800 INFO Total size: 26069.61 MB\n",
      "  1%|          | 166M/27.3G [00:12<35:46, 12.7MiB/s]   "
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    for data_type in ['min','max']:\n",
    "        try:\n",
    "            file_url = f\"https://data.chc.ucsb.edu/products/CHIRTSdaily/v1.0/global_netcdf_p05/T{data_type}/T{data_type}.{year}.nc\"\n",
    "            download_file(file_url, DEST_PATH / \"tmp\"/ f\"T{data_type}_{year}.nc\")\n",
    "            # Subset to PH \n",
    "            ds = xr.open_dataset(DEST_PATH / \"tmp\"/ f\"T{data_type}_{year}.nc\")\n",
    "            ds = ds.sel(latitude=slice(PH_BBOX[1], PH_BBOX[3]), longitude=slice(PH_BBOX[0], PH_BBOX[2]))\n",
    "            ds.to_netcdf(DEST_PATH / f\"CHIRTS_T{data_type}_PH_{year}.nc\")\n",
    "            os.remove(DEST_PATH / \"tmp\"/ f\"T{data_type}_{year}.nc\")\n",
    "        except KeyboardInterrupt:\n",
    "            logger.error(\"Process interrupted using keyboard.\")\n",
    "            break\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-downscaling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
